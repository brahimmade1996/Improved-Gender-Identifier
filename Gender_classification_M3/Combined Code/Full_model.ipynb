{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import requests as requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "from m3inference import M3Inference\n",
    "from collections import OrderedDict\n",
    "#import pprint\n",
    "import urllib.request\n",
    "#import random\n",
    "import re\n",
    "import os\n",
    "import csv \n",
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "import string \n",
    "import operator\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from io import BytesIO\n",
    "from scipy.io import loadmat\n",
    "from m3preprocess import extract_files, preprocess_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows you to run M3 on image datasets and get the performance statistics. <a href=\"https://github.com/euagendas/m3inference\">This M3 implementation code </a> is used.\n",
    "\n",
    "You should specify the following variables when running the notebook:\n",
    "- **dataset**: which dataset you use. Can be **only** one of the following: wiki, IMDB, Twitter, Scholar, OUI, Gender Shade. For new datasets please modify the code for extracting the images and reading the annotations file\n",
    "- **path_to_data**: path to the data (original data is saved here: 175.238.89:/bigdisk/gender_inference/Unpruned_data/) in .zip or .tar format\n",
    "- **path_to_output**: path to where the data will be extracted, as well as where data.jsonl and result.csv will be saved\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Necessary variables to change \n",
    "dataset = 'imdb' #twitter, wiki, imdb, gender_shade, scholar or oui\n",
    "path_to_data = '../../../Desktop/Новая папка/GESIS/Gender_Inference/Unpruned_data/IMDB/imdb_crop.zip'\n",
    "path_to_output = '../../../Desktop/Новая папка/GESIS/Gender_Inference/Unpruned_data/IMDB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Unpack and extract images paths\n",
    "path_to_images = extract_files(dataset, path_to_data, path_to_output)\n",
    "\n",
    "images = []\n",
    "if len(next(os.walk(path_to_images))[1]) == 0: #case when images are in one folder\n",
    "    for image in os.listdir(path_to_images): \n",
    "        if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "            images.append(path_to_images + image)\n",
    "else: #case when images are in several folders\n",
    "    for path in [path_to_images + next(os.walk(path_to_images))[1][n] for n in range(len(next(os.walk(path_to_images))[1]))]:\n",
    "        for image in os.listdir(path+'/'): \n",
    "            if image[-3:] == 'jpg' or image[-3:] == 'png':\n",
    "                images.append(path+'/' + image)\n",
    "            \n",
    "print('Total number of images:', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# preprocess images and create a json file for M3\n",
    "\n",
    "data = {}\n",
    "data['images'] = []\n",
    "for image in images:\n",
    "    preprocess_images(image, 224, 224, skip = False) # specify skip = False if size condition should be ignored (height+width>=400)\n",
    "    data['images'].append({\n",
    "        \"description\":\"\", \n",
    "        \"id\": image.split('/')[-1],\n",
    "        \"img_path\": image, \n",
    "        \"lang\": \"en\", \n",
    "        \"name\": \"\", \n",
    "        \"screen_name\": \"\"\n",
    "    })\n",
    "    \n",
    "with open(path_to_output+'data.jsonl', 'w') as json_file: # json file for m3 is created  \n",
    "    json.dump(data, json_file)\n",
    "\n",
    "_json = path_to_output+'data.jsonl'\n",
    "print('Json saved at ', _json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# run M3 and infer gender\n",
    "\n",
    "def M3_inference(path_to_output, _json):\n",
    "    try:\n",
    "        with open(_json) as json_file:\n",
    "            data = json.load(json_file)\n",
    "        pred = m3.infer(data['images']) #get the predictions from json file\n",
    "        #disc=pprint.pprint(pred)\n",
    "        with open(path_to_output+'predictions.json', 'w') as pred_file:\n",
    "            json.dump(pred, pred_file, indent=3)\n",
    "        print(f'Predictions are finished for {len(pred)} images')\n",
    "\n",
    "        with open(path_to_output+'result.csv', 'w', newline='') as output:  # output file is created\n",
    "            wr = csv.writer(output,quoting=csv.QUOTE_ALL)\n",
    "            wr.writerow(['Imagename','Predicted_Gender', 'Is_Org']) #header row\n",
    "            for tup in pred.items():\n",
    "                gender_conf = tup[1]['gender'] #extracting predictions for gender\n",
    "                gender = max(gender_conf.items(), key=operator.itemgetter(1)) #50% threshold, choosing gender with max confidence score\n",
    "                org = tup[1]['org'] #extracting predictions for org (if several people are presented on image)\n",
    "                is_org = False #boolean variable will be stored in the output file\n",
    "                if org['is-org'] > 0.5:\n",
    "                    is_org = True\n",
    "                wr.writerow([tup[0], gender[0], is_org]) #writing a row for every image with image name, predicted gender and is_org flag\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print (e)\n",
    "\n",
    "m3 = M3Inference()\n",
    "M3_inference(path_to_output, _json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# extract annotations file\n",
    "\n",
    "### for .mat file for IMDB ###\n",
    "def get_names(x):\n",
    "    if len(x)>0:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "### for .mat file for imdb and wiki ###\n",
    "if dataset == 'imdb' or dataset == 'wiki':\n",
    "    path_to_meta =  path_to_output + dataset + \".mat\"\n",
    "    mat = loadmat(path_to_meta)  # load mat-file\n",
    "    mdata = mat[dataset]  # variable in mat file\n",
    "    mdtype = mdata.dtype\n",
    "    ndata = {n: mdata[n][0, 0] for n in mdtype.names}\n",
    "    columns = [n for n, v in ndata.items()]# if v.size == ndata['numIntervals']]\n",
    "\n",
    "    dob = mdata['dob'][0,0][0]\n",
    "    photo_taken = mdata['photo_taken'][0,0][0]\n",
    "    full_path = [mdata['full_path'][0,0][0][n][0] for n in range(len(mdata['full_path'][0,0][0]))]\n",
    "    gender = mdata['gender'][0,0][0]\n",
    "    name = np.array(list(map(get_names, mdata['name'][0,0][0])))\n",
    "    face_location = mdata['face_location'][0,0][0]\n",
    "    face_score = mdata['face_score'][0,0][0]\n",
    "    second_face_score = mdata['second_face_score'][0,0][0]\n",
    "    celeb_id = mdata['celeb_id'][0,0][0]\n",
    "\n",
    "    metadf = pd.DataFrame({\"dob\": dob, \"photo_taken\":photo_taken, \"full_path\":full_path, \"gender\":gender, \"name\":name, \"face_location\":face_location, \"face_score\":face_score, \"second_face_score\":second_face_score},\n",
    "                  index=celeb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TWITTER###\n",
    "metadf = pd.DataFrame()\n",
    "meta_path = '../../../Desktop/Новая папка/GESIS/Gender_Inference/Unpruned_data/Twitter/_a_results32langs/'\n",
    "for file in os.listdir(meta_path):\n",
    "    df = pd.read_csv(meta_path + file)\n",
    "    metadf = metadf.append(df)\n",
    "    \n",
    "metadf.reset_index(inplace = True)\n",
    "metadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../../../Desktop/Новая папка/GESIS/Gender_Inference/Unpruned_data/wiki/wiki/result.csv')\n",
    "#results['Imagename'] = results['Imagename'].apply(lambda x: x[:-4]) for Twitter need to remove .png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf['full_path'] = metadf['full_path'].apply(lambda x: x.split('/')[1]) #removing the folder names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merged = pd.merge(results, metadf, left_on='Imagename', right_on='full_path') #merge results and annotations\n",
    "results_merged['gender'] = results_merged['gender'].apply(lambda x: \"female\" if x == 0 else \"male\") #for wiki\n",
    "#results['gender'] = results['gender'].apply(lambda x: x.lower()) #for twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR TWITTER ##\n",
    "def org(row):\n",
    "    if row['Is_Org'] == True:\n",
    "        return 'orga'\n",
    "    else:\n",
    "        return row['G_Gender']\n",
    "\n",
    "results_merged['G_Gender'] = results_merged.apply(lambda x: org(x), axis=1)\n",
    "results_merged = results_merged[results_merged['indicated_gender:confidence'] >= 0.8][(results_merged['indicated_gender']=='male') | (results_merged['indicated_gender']=='female') | (results_merged['indicated_gender']=='orga')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merged['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_f = '../../../Downloads/imdb_female.csv'\n",
    "# file_m = '../../../Downloads/imdb_male.csv'\n",
    "\n",
    "# female_all = pd.read_csv(file_f, names=['name', 'G_Gender', 'M_Gender'])\n",
    "# male_all= pd.read_csv(file_m)\n",
    "# full_data = pd.concat([female_all, male_all])# \n",
    "# True values\n",
    "y_true = results_merged['gender']\n",
    "# Predicted values\n",
    "#full_data['M_Gender'] = full_data['M_Gender'].apply(lambda x: \"F\" if x == 'female' else \"M\")\n",
    "y_pred = results_merged['G_Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "\n",
    "#printing the metrics\n",
    "metrics_dict=metrics.classification_report(y_true, y_pred,output_dict=True)\n",
    "\n",
    "#precision:\n",
    "print('Precision:',round(metrics_dict['weighted avg']['precision'],4))\n",
    "#Recall\n",
    "print('Recall:',round(metrics_dict['weighted avg']['recall'],4))\n",
    "#F1-score\n",
    "print('F1-score:',round(metrics_dict['weighted avg']['f1-score'],4))\n",
    "#accuracy\n",
    "print('Accuracy:',round(metrics_dict['accuracy'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
